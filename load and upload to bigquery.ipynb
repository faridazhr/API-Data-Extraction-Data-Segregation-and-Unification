{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Data from BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file( \n",
    "r'D:\\JOB\\APSD\\Big Data Platform\\Data\\big-data-xxx-xxx.json')\n",
    "\n",
    "project_id = 'big-data-xxx'\n",
    "client = bigquery.Client(credentials= credentials,project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "   SELECT * FROM `big-data-xxxx.test_dataset01.ex-daily_data` LIMIT 100\"\"\"\n",
    "cloud_data = client.query(sql).to_dataframe()\n",
    "cloud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "   SELECT *\n",
    "   FROM `big-data-xxxx.test_dataset01.test_flight_data_2023`\n",
    "   ORDER BY index\"\"\"\n",
    "cloud_data = client.query(sql).to_dataframe()\n",
    "cloud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_data = cloud_data.set_index('index')\n",
    "cloud_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data Flight from AP2 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(start, end):\n",
    "    ## Create Vessel List\n",
    "    ACTUAL_TIME = []\n",
    "    AIRCRAFT_REG_NO = []\n",
    "    CAPACITY = []\n",
    "    CATEGORY_CODE = []\n",
    "    CHECK_IN_COUNTER = []\n",
    "    CONVEYOR_BELT = []\n",
    "    DATE = []\n",
    "    DESCRIPTION = []\n",
    "    ESTIMATED_TIME = []\n",
    "    FLIGHT_NO = []\n",
    "    FROM_STATION = []\n",
    "    GATE_NUMBER = []\n",
    "    LEG = []\n",
    "    REMARK = []\n",
    "    SCHEDULED_TIME = []\n",
    "    TERMINAL = []\n",
    "    TO_STATION = []\n",
    "\n",
    "    ## Genereate Date\n",
    "    date1 = start\n",
    "    date2 = end\n",
    "    mydates = pd.date_range(date1, date2).to_list()\n",
    "    date = pd.to_datetime(pd.Series(mydates), format='%Y-%m-%d').dt.date\n",
    "\n",
    "    ## Login\n",
    "    url_login = 'https://xxx.angkasapura2.co.id/xxxx'\n",
    "    myobj_login = {\"username\": \"username\",\n",
    "        \"password\": \"password\"}\n",
    "\n",
    "    login = requests.post(url_login, json = myobj_login)\n",
    "    login_response = json.loads(login.text)\n",
    "\n",
    "    ## Get Token\n",
    "    token = login_response['token']\n",
    "\n",
    "    ## Looping Get Data\n",
    "    for i in date:\n",
    "        url_flight = 'https://xxxx.angkasapura2.co.id/xxxx'\n",
    "        myobj_flight = {\"date\": str(i), \"branch\": \"XXX\"}\n",
    "\n",
    "        flight = requests.get(url_flight, headers={'x-access-token': token}, json = myobj_flight)\n",
    "        flight_response = json.loads(flight.text)\n",
    "           \n",
    "        data = flight_response\n",
    "        \n",
    "        ## Store each data to it's own vessel\n",
    "        for i in data['data']:\n",
    "            ACTUAL_TIME.append(i['ACTUAL_TIME'])\n",
    "            AIRCRAFT_REG_NO.append(i['AIRCRAFT_REG_NO'])\n",
    "            CAPACITY.append(i['CAPACITY'])\n",
    "            CATEGORY_CODE.append(i['CATEGORY_CODE'])\n",
    "            CHECK_IN_COUNTER.append(i['CHECK_IN_COUNTER'])\n",
    "            CONVEYOR_BELT.append(i['CONVEYOR_BELT'])\n",
    "            DATE.append(i['DATE'])\n",
    "            DESCRIPTION.append(i['DESCRIPTION'])\n",
    "            ESTIMATED_TIME.append(i['ESTIMATED_TIME'])\n",
    "            FLIGHT_NO.append(i['FLIGHT_NO'])\n",
    "            FROM_STATION.append(i['FROM_STATION'])\n",
    "            GATE_NUMBER.append(i['GATE_NUMBER'])\n",
    "            LEG.append(i['LEG'])\n",
    "            REMARK.append(i['REMARK'])\n",
    "            SCHEDULED_TIME.append(i['SCHEDULED_TIME'])\n",
    "            TERMINAL.append(i['TERMINAL'])\n",
    "            TO_STATION.append(i['TO_STATION'])\n",
    "\n",
    "        ## Convert list data to DataFrame\n",
    "        Dataset = pd.DataFrame()\n",
    "        Dataset['ACTUAL_TIME'] = pd.to_datetime(ACTUAL_TIME, errors = 'coerce')\n",
    "        Dataset['AIRCRAFT_REG_NO'] = AIRCRAFT_REG_NO\n",
    "        Dataset['CAPACITY'] = CAPACITY\n",
    "        Dataset['CATEGORY_CODE'] = CATEGORY_CODE\n",
    "        Dataset['CHECK_IN_COUNTER'] = CHECK_IN_COUNTER\n",
    "        Dataset['CONVEYOR_BELT'] = CONVEYOR_BELT\n",
    "        Dataset['DATE'] = pd.to_datetime(DATE, errors = 'coerce').strftime('%Y-%m-%d')\n",
    "        Dataset['DESCRIPTION'] = DESCRIPTION\n",
    "        Dataset['ESTIMATED_TIME'] = pd.to_datetime(ESTIMATED_TIME, errors = 'coerce')\n",
    "        Dataset['FLIGHT_NO'] = FLIGHT_NO\n",
    "        Dataset['FROM_STATION'] = FROM_STATION\n",
    "        Dataset['GATE_NUMBER'] = GATE_NUMBER\n",
    "        Dataset['LEG'] = LEG\n",
    "        Dataset['REMARK'] = REMARK\n",
    "        Dataset['SCHEDULED_TIME'] = pd.to_datetime(SCHEDULED_TIME, errors = 'coerce')\n",
    "        Dataset['TERMINAL'] = TERMINAL\n",
    "        Dataset['TO_STATION'] = TO_STATION\n",
    "        \n",
    "\n",
    "    return Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last date of data in BigQuery\n",
    "last_date = cloud_data['DATE'].values[-1] + datetime.timedelta(days=1)\n",
    "last_date = last_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# get today's datetime\n",
    "today = datetime.datetime.today() - datetime.timedelta(days=1)\n",
    "today.strftime('%Y-%m-%d')\n",
    "\n",
    "# Collect data from last date of data in BigQuery to today's date\n",
    "new_flight_2023_incomplete = collect_data(last_date, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_flight_2023_incomplete\n",
    "print(new_flight_2023_incomplete.to_string())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat Data from BigQuey and Newest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [cloud_data, new_flight_2023_incomplete]\n",
    "\n",
    "new_flight_2023 = pd.concat(frames)\n",
    "new_flight_2023 = new_flight_2023.reset_index(drop=True)\n",
    "new_flight_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_flight_2023.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_flight_2023.to_csv('flight_data_2023-incomplete.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=r\"D:\\JOB\\APSD\\Big Data Platform\\Data\\big-data-xxxxxx-xxxxxxxxx.json\"\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "table_id = \"big-data-xxxxxx.test_dataset01.test_flight_data_2023\"\n",
    "file_path = r\"D:\\JOB\\APSD\\Big Data Platform\\Data\\flight_data_2023-incomplete.csv\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE  #added to have truncate and insert load\n",
    ")\n",
    "\n",
    "with open(file_path, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_id, job_config=job_config)\n",
    "    \n",
    "job.result()  # Waits for the job to complete.\n",
    "\n",
    "table = client.get_table(table_id)  # Make an API request.\n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(\n",
    "        table.num_rows, len(table.schema), table_id\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
